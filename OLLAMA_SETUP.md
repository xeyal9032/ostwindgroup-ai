# ğŸ¤– Ollama Entegrasyon Rehberi

## ğŸ“¥ **1. Ollama Kurulumu**

### Windows iÃ§in:
1. https://ollama.ai/download adresinden Ollama'yÄ± indirin
2. Kurulum dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n
3. Kurulum tamamlandÄ±ktan sonra Ollama otomatik olarak baÅŸlayacak

### Kurulumu Test Edin:
```bash
ollama --version
```

## ğŸš€ **2. Model Ä°ndirme**

### PopÃ¼ler Modeller:
```bash
# Llama 2 (7B) - HÄ±zlÄ± ve etkili
ollama pull llama2

# Llama 2 (13B) - Daha gÃ¼Ã§lÃ¼ ama yavaÅŸ
ollama pull llama2:13b

# Code Llama - Kod yazma iÃ§in Ã¶zel
ollama pull codellama

# Mistral - HÄ±zlÄ± ve kaliteli
ollama pull mistral

# Gemma - Google'Ä±n aÃ§Ä±k kaynak modeli
ollama pull gemma
```

### Model BoyutlarÄ±:
- **7B modeller**: ~4GB RAM kullanÄ±r
- **13B modeller**: ~8GB RAM kullanÄ±r
- **70B modeller**: ~40GB RAM kullanÄ±r

## ğŸ”§ **3. Ollama Servisini BaÅŸlatma**

### Manuel BaÅŸlatma:
```bash
ollama serve
```

### Otomatik BaÅŸlatma (Windows):
Ollama kurulumu sonrasÄ± otomatik olarak baÅŸlar. EÄŸer baÅŸlamazsa:
1. Windows Services'te "Ollama" servisini bulun
2. Servisi baÅŸlatÄ±n

## ğŸŒ **4. Web Projesi Entegrasyonu**

### Otomatik Entegrasyon:
Projenizde Ollama kontrol paneli otomatik olarak gÃ¶rÃ¼necek:
- âœ… **YeÅŸil nokta**: Ollama Ã§alÄ±ÅŸÄ±yor
- âŒ **KÄ±rmÄ±zÄ± nokta**: Ollama kapalÄ±
- ğŸ”„ **Model seÃ§ici**: Ä°ndirdiÄŸiniz modelleri gÃ¶sterir
- â˜‘ï¸ **"Ollama Kullan"**: Ollama'yÄ± aktif/pasif yapar

### Manuel Test:
```bash
# Ollama API'sini test edin
curl http://localhost:11434/api/tags

# Basit bir test
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "llama2", "prompt": "Merhaba!", "stream": false}'
```

## âš¡ **5. Performans Optimizasyonu**

### GPU DesteÄŸi (NVIDIA):
```bash
# CUDA kurulu olmalÄ±
ollama pull llama2
# GPU otomatik olarak kullanÄ±lacak
```

### RAM Optimizasyonu:
- **8GB RAM**: 7B modeller iÃ§in yeterli
- **16GB RAM**: 13B modeller iÃ§in Ã¶nerilen
- **32GB+ RAM**: 70B modeller iÃ§in gerekli

### CPU Optimizasyonu:
```bash
# CPU thread sayÄ±sÄ±nÄ± ayarlayÄ±n
export OLLAMA_NUM_PARALLEL=4
export OLLAMA_MAX_LOADED_MODELS=2
```

## ğŸ”’ **6. GÃ¼venlik**

### Yerel KullanÄ±m:
- Ollama sadece localhost'ta Ã§alÄ±ÅŸÄ±r (127.0.0.1:11434)
- DÄ±ÅŸarÄ±dan eriÅŸim yok
- API anahtarÄ± gerektirmez

### Firewall:
Windows Firewall Ollama'yÄ± otomatik olarak izin verir.

## ğŸ› **7. Sorun Giderme**

### Ollama BaÅŸlamÄ±yor:
```bash
# Servis durumunu kontrol edin
ollama list

# Manuel baÅŸlatma
ollama serve
```

### Model Ä°ndirme HatasÄ±:
```bash
# Disk alanÄ±nÄ± kontrol edin
ollama list

# Yeniden indirin
ollama pull llama2
```

### YavaÅŸ YanÄ±tlar:
1. Daha kÃ¼Ã§Ã¼k model kullanÄ±n (7B yerine 13B)
2. GPU desteÄŸini kontrol edin
3. RAM kullanÄ±mÄ±nÄ± izleyin

### Web Projesi BaÄŸlanamÄ±yor:
1. Ollama'nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol edin: `ollama list`
2. Port 11434'Ã¼n aÃ§Ä±k olduÄŸunu kontrol edin
3. Browser console'da hata mesajlarÄ±nÄ± kontrol edin

## ğŸ“Š **8. Model KarÅŸÄ±laÅŸtÄ±rmasÄ±**

| Model | Boyut | RAM | HÄ±z | Kalite | Ã–nerilen KullanÄ±m |
|-------|-------|-----|-----|--------|-------------------|
| llama2:7b | 3.8GB | 4GB | â­â­â­â­â­ | â­â­â­â­ | Genel kullanÄ±m |
| llama2:13b | 7.3GB | 8GB | â­â­â­â­ | â­â­â­â­â­ | Daha kaliteli yanÄ±tlar |
| codellama:7b | 3.8GB | 4GB | â­â­â­â­â­ | â­â­â­â­â­ | Kod yazma |
| mistral:7b | 4.1GB | 4GB | â­â­â­â­â­ | â­â­â­â­â­ | HÄ±zlÄ± ve kaliteli |
| gemma:7b | 5.4GB | 6GB | â­â­â­â­ | â­â­â­â­â­ | Google kalitesi |

## ğŸ¯ **9. KullanÄ±m Ä°puÃ§larÄ±**

### En Ä°yi Deneyim Ä°Ã§in:
1. **Ä°lk kurulum**: `llama2:7b` ile baÅŸlayÄ±n
2. **RAM yeterliyse**: `llama2:13b` kullanÄ±n
3. **Kod yazÄ±yorsanÄ±z**: `codellama` kullanÄ±n
4. **HÄ±z Ã¶nemliyse**: `mistral` kullanÄ±n

### Prompt Ä°puÃ§larÄ±:
- TÃ¼rkÃ§e sorular iÃ§in: "TÃ¼rkÃ§e olarak yanÄ±tla: [sorunuz]"
- Kod iÃ§in: "Bu kodu aÃ§Ä±kla: [kod]"
- Ã–zet iÃ§in: "Ã–zetle: [metin]"

## ğŸš€ **10. GeliÅŸmiÅŸ Ã–zellikler**

### Ã–zel Model EÄŸitimi:
```bash
# Kendi modelinizi oluÅŸturun
ollama create mymodel -f Modelfile
```

### Batch Ä°ÅŸlemler:
```bash
# Birden fazla modeli paralel Ã§alÄ±ÅŸtÄ±rÄ±n
ollama pull llama2 codellama mistral
```

### API Entegrasyonu:
```javascript
// JavaScript ile Ollama API
const response = await fetch('http://localhost:11434/api/generate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    model: 'llama2',
    prompt: 'Merhaba!',
    stream: false
  })
});
```

---

## âœ… **Kurulum TamamlandÄ±!**

ArtÄ±k web projenizde:
- ğŸ¤– **Ollama kontrol paneli** gÃ¶rÃ¼necek
- ğŸ”„ **Model seÃ§imi** yapabileceksiniz  
- âš¡ **Yerel AI** kullanabileceksiniz
- ğŸ”’ **API anahtarÄ± gerektirmeyecek**
- ğŸ’° **Tamamen Ã¼cretsiz** olacak

**Not**: Ollama sadece bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸÄ±r. BaÅŸka kullanÄ±cÄ±lar Ollama'nÄ±zÄ± kullanamaz.
